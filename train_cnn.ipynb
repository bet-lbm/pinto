{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bet-lbm/pinto/blob/master/train_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rkRPI46TmbGB",
        "colab_type": "code",
        "outputId": "1cd6b82a-1c41-4575-9ef3-fe8b0bfdbc13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bet-lbm/dl-dataset.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dl-dataset'...\n",
            "remote: Enumerating objects: 3028, done.\u001b[K\n",
            "remote: Counting objects: 100% (3028/3028), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3027/3027), done.\u001b[K\n",
            "remote: Total 3028 (delta 1), reused 3028 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3028/3028), 63.02 MiB | 10.22 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O_THIyMowcVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOP9Qt4Mwkgw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# limpiar seccion de tensorflow\n",
        "K.clear_session()\n",
        "\n",
        "#rutas de DataSet\n",
        "data_entrenamiento = './dl-dataset/train'\n",
        "data_validacion = './dl-dataset/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wddq_VDuwypb",
        "colab_type": "code",
        "outputId": "c2d63586-eaf8-449f-9f69-f684b1b19ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        }
      },
      "cell_type": "code",
      "source": [
        "# parametros\n",
        "epocas = 20 # numero de veces que vamos a iterar\n",
        "longitud, altura = 150, 150 #tamaño de procesamiento de nuestras imagenes \n",
        "batch_size = 32 #numero de imagenes que vamos a mandar a procesar en cada uno de los pasos\n",
        "pasos = 1000 #numero de veces que se va a procesar la informacion en cada una de la epocas\n",
        "validation_steps = 200 #pasos de validacion \n",
        "filtroConv1 = 32 #filtros en la convolucion el numero de filtros\n",
        "filtroConv2 = 64 \n",
        "tamano_filtro1 = (3, 3) #tamaño del filtro altura de 3 y longitud de 3\n",
        "tamano_filtro2 = (2, 2)  #tamaño del filtro altura de 3 y longitud de 3\n",
        "tamano_pool = (2, 2) \n",
        "clases = 3  # gato perro gorila\n",
        "lr = 0.0005 # ajustes de la red neuronal para acercarse para una solucion optima numero pequeño\n",
        "\n",
        "#pre procesamiento de imagenes \n",
        "entrenamieto_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # rescala cada uno de los pixeles tiene un rango de 0 a 255 => los valores de pixeles de 0 a 1\n",
        "    shear_range=0.3, #genera imagenes y las inclina \n",
        "    zoom_range=0.3, #realiza zoom a la imagenes\n",
        "    horizontal_flip=True #toma imagen y la invierte\n",
        ")\n",
        "\n",
        "validacion_datagen=ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "#generar la imagenes que vamos a usar para entrenar con preprocesamiento \n",
        "imagen_entrenamiento = entrenamieto_datagen.flow_from_directory(\n",
        "    data_entrenamiento,# entra en el directorio de entrenamiento\n",
        "    target_size=(altura, longitud),# va a procesar a una altura y longitud especifica \n",
        "    batch_size= batch_size, # va procesar en un batch de 32\n",
        "    class_mode='categorical' # va a procesar como categoria etiquetas perro , gato, gorila\n",
        ")\n",
        "imagen_validacion = validacion_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size = (altura, longitud),\n",
        "    batch_size = batch_size,\n",
        "    class_mode= 'categorical'\n",
        ")\n",
        "\n",
        "#Creamos nuestra red convolucional\n",
        "cnn = Sequential() # nuestra red nueronal es sequencial varias capas apiladas\n",
        "\n",
        "cnn.add(Convolution2D(filtroConv1,tamano_filtro1,padding='same',input_shape=(altura,longitud,3),activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Convolution2D(filtroConv2,tamano_filtro2,padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "#empezamos nuestra clasificacion \n",
        "cnn.add(Flatten())#imagen muy profunda pero muy pequeña se vuelve plana en una sola dimension que tiene la informacion de nuestra red neuronal\n",
        "cnn.add(Dense(256,activation='relu'))#le decimos que va a tener 256 neuronas y de activacion relu\n",
        "cnn.add(Dropout(0.5))# a la capa Dense vamos a apagarle el 50% de las neuronas en cada paso esto se hace  para evitar sobre ajustar\n",
        "cnn.add(Dense(clases, activation='softmax')) # solo 3 neuronas y softmax nos ayuda a decir que esta imagen que la imagen que me \n",
        " #diste es 80% de probabilidad que sea perro,15% que sea gato y 5% que sea gorila \n",
        "\n",
        "#durante el entrenamiento nuestra funcion de perdida es categorical_crossentropy, el optimizador es Adam un un leraning read lr=0.0005\n",
        "# y la metrica es accuracy que es que tan bien esta aprendiendo nuestra red nueronal\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy']) \n",
        "#vamos a entrenar con imagen de entrenamiento, vamos a correrlo cada epoca con 1000 pasos, el numero de epocas, nuestras imagenes de validacion, tantos pasos de validadion va a correr por cada epoca\n",
        "cnn.fit(imagen_entrenamiento,steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=validation_steps)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 999 images belonging to 3 classes.\n",
            "Found 2043 images belonging to 3 classes.\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 288s 288ms/step - loss: 0.6751 - acc: 0.6747 - val_loss: 0.6316 - val_acc: 0.7056\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 283s 283ms/step - loss: 0.3563 - acc: 0.8440 - val_loss: 0.8322 - val_acc: 0.7071\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 282s 282ms/step - loss: 0.2158 - acc: 0.9124 - val_loss: 1.0079 - val_acc: 0.6912\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 282s 282ms/step - loss: 0.1381 - acc: 0.9484 - val_loss: 1.0355 - val_acc: 0.7157\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 282s 282ms/step - loss: 0.1012 - acc: 0.9633 - val_loss: 1.2445 - val_acc: 0.7165\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 281s 281ms/step - loss: 0.0891 - acc: 0.9676 - val_loss: 1.3995 - val_acc: 0.7193\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 283s 283ms/step - loss: 0.0837 - acc: 0.9717 - val_loss: 1.2181 - val_acc: 0.7085\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 283s 283ms/step - loss: 0.0718 - acc: 0.9752 - val_loss: 1.5451 - val_acc: 0.7154\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 283s 283ms/step - loss: 0.0670 - acc: 0.9776 - val_loss: 1.5826 - val_acc: 0.6991\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 282s 282ms/step - loss: 0.0641 - acc: 0.9777 - val_loss: 1.5223 - val_acc: 0.7308\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 283s 283ms/step - loss: 0.0474 - acc: 0.9837 - val_loss: 1.4968 - val_acc: 0.7178\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 283s 283ms/step - loss: 0.0540 - acc: 0.9825 - val_loss: 1.6863 - val_acc: 0.7192\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 282s 282ms/step - loss: 0.0417 - acc: 0.9851 - val_loss: 1.6540 - val_acc: 0.7352\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 281s 281ms/step - loss: 0.0437 - acc: 0.9864 - val_loss: 1.6924 - val_acc: 0.7350\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 280s 280ms/step - loss: 0.0518 - acc: 0.9841 - val_loss: 1.8961 - val_acc: 0.7325\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 282s 282ms/step - loss: 0.0365 - acc: 0.9880 - val_loss: 1.7178 - val_acc: 0.7377\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 282s 282ms/step - loss: 0.0357 - acc: 0.9882 - val_loss: 1.6742 - val_acc: 0.7240\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 283s 283ms/step - loss: 0.0362 - acc: 0.9883 - val_loss: 1.8468 - val_acc: 0.7281\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 280s 280ms/step - loss: 0.0375 - acc: 0.9878 - val_loss: 2.0033 - val_acc: 0.7338\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 286s 286ms/step - loss: 0.0364 - acc: 0.9877 - val_loss: 2.1686 - val_acc: 0.7291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd976059048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "YvcjFISiyCXy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#guarda nuestro modelo en un archivo\n",
        "dir='./modelo'\n",
        "if not os.path.exists(dir):\n",
        "    os.mkdir(dir)\n",
        "cnn.save('./modelo/modelo.h5')\n",
        "cnn.save_weights('./modelo/pesos.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cnpx-ZjjL6TA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# `Predicción`"
      ]
    },
    {
      "metadata": {
        "id": "0svxPWn6RHzV",
        "colab_type": "code",
        "outputId": "21367cc8-b327-4386-9a1b-000175d25429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}